[
  {
    "objectID": "MP00.html",
    "href": "MP00.html",
    "title": "Will Peters STA9750-2024-FALL",
    "section": "",
    "text": "Hello,\nThank you for having a look at my Website\nIf you want to know more about me, feel free to check out my Linkedin\nThis will be further updated as we go along further.\n\nTest"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Will Peters STA9750-2024-FALL",
    "section": "",
    "text": "Hello,\nThank you for having a look at my Website\nIf you want to know more about me, feel free to check out my Linkedin\nThis will be further updated as we go along further."
  },
  {
    "objectID": "MP02.html",
    "href": "MP02.html",
    "title": "Will Peters STA9750-2024-FALL MP02",
    "section": "",
    "text": "Initially we start by installing all the libraries for R if you are interested in utilizing, and running it on your own.\n\nlibrary(scales) \nlibrary(stringr) \nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr) \nlibrary(foreach)\n\n\nAttaching package: 'foreach'\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\nlibrary(doParallel)\n\nLoading required package: iterators\nLoading required package: parallel\n\nlibrary(ggplot2) \nlibrary(tidyr) \nlibrary(plotly) \n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(knitr)\n\nNext we install a function to download the data sources from the imdb website and running it across the different file names as below. This generates the parameter of Base_url, Fname_ext and FILE_URL and the function of get_imdb_file with the input being the fname you see below.\n\nget_imdb_file &lt;- function(fname){ \n  BASE_URL &lt;- \"https://datasets.imdbws.com/\" \n  fname_ext &lt;- paste0(fname, \".tsv.gz\") \n  if(!file.exists(fname_ext)){ \n    FILE_URL &lt;- paste0(BASE_URL, fname_ext) \n    download.file(FILE_URL, \n                  destfile = fname_ext) \n  } \n  as.data.frame(readr::read_tsv(fname_ext, lazy=FALSE)) \n  }\n\nTITLE_RATINGS &lt;- get_imdb_file(\"title.ratings\") |&gt; filter(numVotes &gt;= 100)\n\nRows: 1490228 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): tconst\ndbl (2): averageRating, numVotes\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n'TITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\") |&gt; semi_join(TITLE_RATINGS, join_by(tconst == tconst))'\n\n[1] \"TITLE_PRINCIPALS &lt;- get_imdb_file(\\\"title.principals\\\") |&gt; semi_join(TITLE_RATINGS, join_by(tconst == tconst))\"\n\nTITLE_PRINCIPALS &lt;- as.data.frame(readr::read_csv(\"title_principals_small.csv\", lazy=FALSE))\n\nRows: 6586689 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): tconst, nconst, category, job, characters\ndbl (1): ordering\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_BASICS &lt;- get_imdb_file(\"title.basics\") \n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 11176312 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (8): tconst, titleType, primaryTitle, originalTitle, startYear, endYear,...\ndbl (1): isAdult\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt; \n  semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\nTITLE_CREW &lt;- get_imdb_file(\"title.crew\") \n\nRows: 10517985 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): tconst, directors, writers\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_CREW &lt;- TITLE_CREW |&gt; \n  semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\nTITLE_EPISODES &lt;- get_imdb_file(\"title.episode\") \n\nRows: 8583561 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (4): tconst, parentTconst, seasonNumber, episodeNumber\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt; \n  semi_join(TITLE_RATINGS, join_by(tconst == tconst)) \nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt; \n  semi_join(TITLE_RATINGS, join_by(parentTconst == tconst))\n\nNAME_BASICS &lt;- get_imdb_file(\"name.basics\") \n\nRows: 13886887 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (6): nconst, primaryName, birthYear, deathYear, primaryProfession, known...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nNAME_BASICS &lt;- NAME_BASICS |&gt; filter(str_count(knownForTitles,\",\") &gt; 1)\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1, TITLE_EPISODES_2) |&gt; distinct() \n\nThe purpose of the below lines is to remove the components of the TITLE_EPISODES as the bit of code above binds it into the data total.\n\nrm(TITLE_EPISODES_1) \nrm(TITLE_EPISODES_2)\n\nThe mutating feature is transforming the columns and providing the datatype such that it will be easier to read and transform later. Task 1\n\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n  mutate(birthYear = as.numeric(birthYear), \n         deathYear = as.numeric(deathYear)) \n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `birthYear = as.numeric(birthYear)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt; \n  mutate(startYear = as.numeric(startYear), \n         endYear = as.numeric(endYear),\n         runtimeMinutes = as.numeric(runtimeMinutes), \n         isAdult = as.logical(isAdult))\n\nWarning: There were 3 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `startYear = as.numeric(startYear)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings.\n\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt; \n  mutate(seasonNumber = as.numeric(seasonNumber), \n         episodeNumber = as.numeric(episodeNumber))\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `seasonNumber = as.numeric(seasonNumber)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt; \n  mutate(ordering = as.numeric(ordering))\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt; \n  mutate(averageRating = as.numeric(averageRating), \n         numVotes = as.numeric(numVotes))\n\nprint(TITLE_BASICS |&gt; \n        count(titleType, name = \"Countrows\")|&gt;\n        rename(Type=titleType,'Number of media'=Countrows))\n\n           Type Number of media\n1         movie          132336\n2         short           16735\n3     tvEpisode          156904\n4  tvMiniSeries            5939\n5       tvMovie           15056\n6      tvSeries           30021\n7       tvShort             410\n8     tvSpecial            3066\n9         video            9347\n10    videoGame            4693\n\n\nTask 2\n1.\nAnswer is in our data set there are 132,171 Movies, 29,964 TV Series and 156,592 Episodes\n2.\n\nkable(NAME_BASICS |&gt; \n         filter (is.na(deathYear),birthYear&gt;1906) |&gt; \n         arrange(birthYear) |&gt; \n         rename(Name = primaryName, Year_of_Birth = birthYear,Year_of_Death = deathYear,Profession = primaryProfession) |&gt;\n         select(-Profession,-nconst,-knownForTitles) |&gt;\n         head(10),align = \"l\") \n\n\n\n\nName\nYear_of_Birth\nYear_of_Death\n\n\n\n\nAlberto Albani Barbieri\n1907\nNA\n\n\nYevdokiya Alekseyeva\n1907\nNA\n\n\nMalcolm Baker-Smith\n1907\nNA\n\n\nVineta Bastian-Klinger\n1907\nNA\n\n\nGretel Berndt\n1907\nNA\n\n\nEdgar Blatt\n1907\nNA\n\n\nRonald Brantford\n1907\nNA\n\n\nElisa Carreira\n1907\nNA\n\n\nHemchandra Chunder\n1907\nNA\n\n\nJohn Clein\n1907\nNA\n\n\n\n\n\nThe data is showing the list of 10 people as being the oldest living under the assumption that the death year NA is accurate, as the oldest living person was born in 1907. Overall inaccurate, it would require an additional data source to validate the information’\n‘3.’\n\nkable (TITLE_RATINGS |&gt; \n         filter(averageRating == 10.0,numVotes &gt;= 200000) |&gt; \n         inner_join(TITLE_BASICS |&gt; \n              select(tconst,primaryTitle),join_by(tconst == tconst)) |&gt;\n         rename(EpisodeTitle = primaryTitle) |&gt; \n         inner_join(TITLE_EPISODES |&gt; \n              select(tconst,parentTconst),join_by(tconst == tconst)) |&gt;\n         inner_join(TITLE_BASICS |&gt; \n              select(tconst,primaryTitle),join_by(parentTconst == tconst)) |&gt;  \n         rename(SeriesTitle = primaryTitle) |&gt;\n         select(-tconst,-parentTconst) |&gt;\n         rename(Rating = averageRating,'Number of votes' = numVotes,Episode=EpisodeTitle,Series=SeriesTitle),align = \"l\")\n\n\n\n\nRating\nNumber of votes\nEpisode\nSeries\n\n\n\n\n10\n230179\nOzymandias\nBreaking Bad\n\n\n\n\n\n‘As you can see with a huge 230,000 votes it is the episode Ozymandis in the series Breaking Bad that received a perfect 10’\n‘4.’\n\nkable(NAME_BASICS |&gt; \n         filter(primaryName == \"Mark Hamill\") |&gt; \n         separate_longer_delim(knownForTitles,\",\") |&gt; \n         inner_join(TITLE_RATINGS,join_by(knownForTitles == tconst)) |&gt; \n         inner_join(TITLE_BASICS |&gt; \n               select(tconst,primaryTitle),join_by(knownForTitles == tconst)) |&gt; \n         arrange(desc(numVotes)) |&gt;\n         select(-nconst,-birthYear,-deathYear,-primaryProfession,-knownForTitles) |&gt;\n         rename(Name = primaryName,Rating = averageRating,'Number of Votes' = numVotes,Title=primaryTitle),align=\"l\")\n\n\n\n\n\n\n\n\n\n\nName\nRating\nNumber of Votes\nTitle\n\n\n\n\nMark Hamill\n8.6\n1475025\nStar Wars: Episode IV - A New Hope\n\n\nMark Hamill\n8.7\n1406127\nStar Wars: Episode V - The Empire Strikes Back\n\n\nMark Hamill\n8.3\n1140557\nStar Wars: Episode VI - Return of the Jedi\n\n\nMark Hamill\n6.9\n682965\nStar Wars: Episode VIII - The Last Jedi\n\n\n\n\n\n‘My argument for this would be the Starwars episodes are Mark Hamills primary claim to fame, specifically Episode, 4,5, 6 and 8 in that order’\n‘5.’\n\nkable(TITLE_EPISODES |&gt; \n        count(parentTconst, name = \"Countrows\") |&gt; \n        filter(Countrows &gt;= 12) |&gt; \n        inner_join(TITLE_BASICS |&gt; \n               filter(titleType == \"tvSeries\")|&gt; \n               select (primaryTitle,tconst), join_by(parentTconst == tconst))|&gt; \n        inner_join(TITLE_RATINGS,join_by (parentTconst == tconst)) |&gt; \n        arrange(desc(averageRating)) |&gt; \n        select(-parentTconst) |&gt;\n        rename('Number of episodes'=Countrows,'Tv series'=primaryTitle,'Number of votes'=numVotes,Rating=averageRating)  |&gt;\n        head(10),align = \"l\")\n\n\n\n\nNumber of episodes\nTv series\nRating\nNumber of votes\n\n\n\n\n101\nJogandofoddaci\n9.8\n178\n\n\n318\nCraft Games\n9.7\n150\n\n\n134\nChoufli Hal\n9.7\n2930\n\n\n212\nPrime Time\n9.7\n181\n\n\n74\nFriday Five Sharp\n9.7\n4516\n\n\n66\nFreaking Fucking Games\n9.6\n136\n\n\n238\nMarmadesam\n9.6\n907\n\n\n171\nOneyPlays\n9.6\n226\n\n\n170\nThe Why Files\n9.6\n868\n\n\n12\nArkadas Canlisi\n9.6\n4185\n\n\n\n\n\n‘Tied for first would be Craft games, Jogandofoddaci, Chofli Hal, Prime time and Friday Five Sharp each having over 50 episodes but low vote counts’\n‘6.’\n\nGRAPH_INFORMATION &lt;- TITLE_BASICS |&gt; \n  filter(primaryTitle == \"Happy Days\") |&gt; \n  inner_join(TITLE_EPISODES,join_by (tconst == parentTconst)) |&gt; \n  inner_join (TITLE_RATINGS,join_by (tconst.y == tconst))\n\nggplot(GRAPH_INFORMATION,aes(x = seasonNumber, y = averageRating)) + \n  geom_point(color = \"blue\", size = 3) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(title=\"Happy Days Seasonal performance\", x = \"Season\", y = \"Rating\") + \n  theme_classic()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n‘From this analysis we can see that the data tended to be on a seasonal decline, however my argument would be that Season 7,8 were the lowest points and then went out with better episodes in season 12’\n‘Task 3 I am going to be saying the success metrics is the rounded average rating such that 5.4 is treated as 5 and 5.6 is treated as 6 added with the number of digits in the votes’\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt; \n  mutate(Success_measure = round(averageRating) + ceiling(log10(abs(numVotes))))\n\n‘I have created a separe dataset for the list of successful movies with wider details to not show too much information’\n\nSuccessful_Movies &lt;- TITLE_RATINGS |&gt;\n  inner_join(TITLE_BASICS |&gt; \n               filter(titleType == \"movie\"), join_by(tconst == tconst)) |&gt; \n  arrange(desc(Success_measure),desc(averageRating))\n\n‘3.1’\n\nkable(Successful_Movies |&gt; \n        select(-tconst,-titleType,-originalTitle,-isAdult,-endYear,-runtimeMinutes,-genres) |&gt;\n        head(5)|&gt;\n        rename(Rating = averageRating,'Number of votes'=numVotes,'Success measure' = Success_measure,Title=primaryTitle,'Release Year' = startYear),align = \"l\")\n\n\n\n\n\n\n\n\n\n\n\nRating\nNumber of votes\nSuccess measure\nTitle\nRelease Year\n\n\n\n\n9.3\n2953606\n16\nThe Shawshank Redemption\n1994\n\n\n9.2\n2059043\n16\nThe Godfather\n1972\n\n\n9.0\n1391342\n16\nThe Godfather Part II\n1974\n\n\n9.0\n1481655\n16\nSchindler’s List\n1993\n\n\n9.0\n2022057\n16\nThe Lord of the Rings: The Return of the King\n2003\n\n\n\n\n\n‘The top 5 movies were The Shawshank Redemption, The Godfather, The Godfather Part II, Schindlers List, The Lord of the Rings: The Return of the King all of which were iconic movies and box office successes’\n‘3.2’\n\nkable(TITLE_RATINGS |&gt;\n        filter(numVotes &gt;= 10000) |&gt; \n        inner_join(TITLE_BASICS |&gt; \n                     filter(titleType == \"movie\"), join_by(tconst == tconst)) |&gt; \n        arrange(Success_measure,averageRating) |&gt; \n        head(5)|&gt;\n        select(-tconst,-originalTitle,-titleType,-isAdult,-endYear,-runtimeMinutes,-genres)|&gt;\n        rename(Rating = averageRating,'Number of Votes' = numVotes,'Success Measure' = Success_measure,Title = primaryTitle,'Release Year' = startYear), align = \"l\")\n\n\n\n\n\n\n\n\n\n\n\nRating\nNumber of Votes\nSuccess Measure\nTitle\nRelease Year\n\n\n\n\n1.0\n10212\n6\n321 Action\n2020\n\n\n1.0\n74159\n6\nReis\n2017\n\n\n1.0\n39461\n6\nCumali Ceber: Allah Seni Alsin\n2017\n\n\n1.2\n14932\n6\nDaniel the Wizard\n2004\n\n\n1.2\n20685\n6\n15/07: Break of Dawn\n2021\n\n\n\n\n\n‘Given my metrics I came up with 321 Action (10210 Votes 1.0 rating success measure of 6),Reis (74155 votes,1 Average Rating, success measure of 6) and Cumali Ceber: Allah Seni Alsin (39456 votes, 1 average rating, success measure of 6)’\n‘3.3’\n‘For my actor I selected Brad Pitt and a score above 11’\n\nkable(NAME_BASICS |&gt; \n        filter(primaryName == \"Brad Pitt\") |&gt; \n        separate_longer_delim(knownForTitles, \",\") |&gt; \n        inner_join(TITLE_RATINGS |&gt; \n            filter(Success_measure &gt;= \"10\"), join_by(knownForTitles == tconst)) |&gt;\n        inner_join(TITLE_BASICS |&gt; \n            select(primaryTitle,tconst), join_by(knownForTitles == tconst))|&gt;\n      select(-nconst,-knownForTitles,-deathYear,-primaryProfession)|&gt;\n        rename(Name = primaryName,'Year of Birth' = birthYear,Rating = averageRating,'Number of Votes' = numVotes,'Success measure' = Success_measure,Title=primaryTitle),align=\"l\")\n\n\n\n\n\n\n\n\n\n\n\n\nName\nYear of Birth\nRating\nNumber of Votes\nSuccess measure\nTitle\n\n\n\n\nBrad Pitt\n1963\n8.8\n2385636\n16\nFight Club\n\n\nBrad Pitt\n1963\n6.5\n552901\n12\nMr. & Mrs. Smith\n\n\nBrad Pitt\n1963\n7.6\n474560\n14\nMoneyball\n\n\nBrad Pitt\n1963\n8.0\n654805\n14\n12 Monkeys\n\n\n\n\n\n‘Brad Pitt has been in 4 movies above 10 success points with the 4 being Fight Club, Moneyball, 12 Monkeys, Mr & Mrs Smith’\n‘3.4’\n‘The spot check validation is average Ratings above 9 and lowest success_measure (i.e.minimal view)’\n\nkable(TITLE_RATINGS |&gt; \n        filter(Success_measure &lt;= 12) |&gt; \n        filter(averageRating &gt;= 9) |&gt; \n        inner_join(TITLE_BASICS |&gt; \n        filter(titleType == \"movie\"), join_by(tconst == tconst)) |&gt; \n        arrange(numVotes,Success_measure,desc(averageRating)) |&gt; \n        select(-tconst,-titleType,-originalTitle,-isAdult,-endYear,-runtimeMinutes,-genres) |&gt;\n        rename('Release year' = startYear, Title = primaryTitle,Rating = averageRating,'Success measure' = Success_measure,'Number of votes' = numVotes) |&gt;\n        head(3),align = \"l\")\n\n\n\n\n\n\n\n\n\n\n\nRating\nNumber of votes\nSuccess measure\nTitle\nRelease year\n\n\n\n\n9.9\n100\n12\nYou Are the Apple of My Eye\n2024\n\n\n9.8\n100\n12\nPop Lock ’n Roll\n2016\n\n\n9.6\n100\n12\nAramudaitha Kombu\n2023\n\n\n\n\n\n‘The three movies were Aramudaitha Kombu, Carving the Divie and Pop Lock n Roll which I have never heard of and so did not perform well in terms of the success measure that I crafted’\n‘3.5’\n‘I think a numerical threshold for a project to be a success is if the success criteria is above 14 because that means that either the project got above 9.5 and 1000+ reviews or over a million reviews and was above a 6.5 average rating.’\n‘Task 4’\n‘for this one genre is aggregated with each title potentially having multiple genres to treat this we are going to include a table with each row being a genre per movie’\n‘Had to also remove nulls’\n\nTITLE_BASICS_GENRE &lt;- TITLE_BASICS |&gt; \n  separate_longer_delim(genres, \",\") |&gt;\n  filter(titleType == \"movie\") |&gt; \n  inner_join(TITLE_RATINGS |&gt; \n               select (Success_measure,tconst), join_by(tconst == tconst)) |&gt;\n  filter(Success_measure &gt;= 14) |&gt; \n  mutate(decade=round(startYear,-1))\n\n\ngenre_counts &lt;- TITLE_BASICS_GENRE |&gt; \n  group_by(decade, genres) |&gt; \n  summarize(count = n())\n\n`summarise()` has grouped output by 'decade'. You can override using the\n`.groups` argument.\n\n\n‘Added a filter to only show where count over 12 so to not over lap it’\n\nggplot(genre_counts, aes(x = decade, y = count, fill = genres)) +\n           geom_bar(stat = \"identity\") + \n           geom_text(aes(label = ifelse(count &gt; 12, count, \"\")), position =                  position_stack(vjust = 0.5)) + \n           labs(title = \"Number of Movies by Genre and Decade\") + \n           xlab(\"Decade\") + \n           ylab(\"Number of Movies\") + \n           scale_x_continuous(breaks = seq(1920, 2020, by = 10), labels = paste0            (seq(1920, 2020, by = 10), \"s\")) + \n           ggtitle(label = \"Number of Movies by Genre and Decade\")\n\n\n\n\n\n\n\n\n‘Drama seems to be the most successful from 1920-2020’\n\ntotal_successes &lt;- genre_counts |&gt; \n  group_by(decade) |&gt; \n  summarize(total_success = sum(count))\n\n\ngenre_counts_total &lt;- genre_counts |&gt; \n  left_join(total_successes, by = \"decade\") |&gt; \n  mutate(percentage_of_count = count/total_success)\n\n\nggplot(genre_counts_total, aes(x = decade, y = percentage_of_count, color = genres,group = genres, text = paste0(round(percentage_of_count*100, 0), \"%\"))) +\n           geom_line() + \n           geom_point() + \n           labs(title = \"Percentage of Total Successes by Genre and Year\", x = \"Year\", y = \"Percentage of Total Successes\") + \n           scale_x_continuous(breaks = seq(1920, 2020, by = 10), labels = paste0(seq(1920, 2020, by = 10), \"s\")) + \n           scale_y_continuous(labels = scales::percent) + ggtitle(label = \"Number of Movies by Genre and Decade\")\n\n\n\n\n\n\n\n\n‘4.2’ ‘I would claim the genre that has had the most consistent success movies would be Drama movies always being more than 20% of the share of successful movies by decade’ ‘I would claim that the genre that fell out of favor the most is Romance, as in 1930 it had a 20% share of the success movies however that has dropped to 3% in the 2020s’\n‘4.3 Drama has produced the most successes in 2010s and 2020s, primarily driven by the sheer volume although not having a bad success conversion of movies, the conversion tends to be middle of the pack when compared to other genres’\n\nkable(TITLE_BASICS |&gt; \n         separate_longer_delim(genres, \",\") |&gt; \n         filter(titleType == \"movie\") |&gt; \n         inner_join(TITLE_RATINGS |&gt; \n         select (Success_measure,tconst), join_by(tconst == tconst)) |&gt; \n         mutate(Success=Success_measure &gt;= 14) |&gt; \n         mutate(decade=round(startYear,-1)) |&gt; \n         filter(decade &gt;= 2010) |&gt; \n         group_by(decade,genres) |&gt; \n         summarize(movies = n(), successful_movies = sum(Success==TRUE)) |&gt;\n         mutate(percentage_success = percent(successful_movies/movies)) |&gt;\n         filter(successful_movies != 0)) \n\n`summarise()` has grouped output by 'decade'. You can override using the\n`.groups` argument.\n\n\n\n\n\ndecade\ngenres\nmovies\nsuccessful_movies\npercentage_success\n\n\n\n\n2010\nAction\n3745\n61\n1.629%\n\n\n2010\nAdventure\n1925\n50\n2.597%\n\n\n2010\nAnimation\n855\n20\n2.339%\n\n\n2010\nBiography\n1268\n32\n2.524%\n\n\n2010\nComedy\n8816\n42\n0.476%\n\n\n2010\nCrime\n2953\n38\n1.287%\n\n\n2010\nDrama\n14322\n144\n1.005%\n\n\n2010\nFamily\n1359\n10\n0.736%\n\n\n2010\nFantasy\n1120\n20\n1.786%\n\n\n2010\nHistory\n984\n8\n0.813%\n\n\n2010\nHorror\n3465\n6\n0.173%\n\n\n2010\nMusic\n807\n2\n0.248%\n\n\n2010\nMusical\n302\n2\n0.662%\n\n\n2010\nMystery\n1599\n28\n1.751%\n\n\n2010\nRomance\n3925\n22\n0.561%\n\n\n2010\nSci-Fi\n958\n21\n2.192%\n\n\n2010\nSport\n532\n5\n0.940%\n\n\n2010\nThriller\n3760\n34\n0.904%\n\n\n2010\nWar\n410\n7\n1.707%\n\n\n2010\nWestern\n105\n2\n1.905%\n\n\n2020\nAction\n5542\n61\n1.1007%\n\n\n2020\nAdventure\n2787\n47\n1.6864%\n\n\n2020\nAnimation\n1264\n20\n1.5823%\n\n\n2020\nBiography\n2011\n29\n1.4421%\n\n\n2020\nComedy\n11448\n44\n0.3843%\n\n\n2020\nCrime\n4107\n27\n0.6574%\n\n\n2020\nDocumentary\n5421\n3\n0.0553%\n\n\n2020\nDrama\n19861\n125\n0.6294%\n\n\n2020\nFamily\n1858\n3\n0.1615%\n\n\n2020\nFantasy\n1610\n10\n0.6211%\n\n\n2020\nHistory\n1461\n12\n0.8214%\n\n\n2020\nHorror\n5665\n3\n0.0530%\n\n\n2020\nMusic\n1063\n7\n0.6585%\n\n\n2020\nMusical\n335\n1\n0.2985%\n\n\n2020\nMystery\n2870\n13\n0.4530%\n\n\n2020\nRomance\n4619\n14\n0.3031%\n\n\n2020\nSci-Fi\n1561\n11\n0.7047%\n\n\n2020\nSport\n814\n2\n0.2457%\n\n\n2020\nThriller\n6728\n20\n0.2973%\n\n\n2020\nWar\n534\n3\n0.5618%\n\n\n2020\n\n106\n1\n0.9434%\n\n\n\n\n\n‘4.4 Action as genre has become more popular for successful movies moving from 2% in the 1950s to 14% in the 2020s so has seen a considerable rise’\n‘Overall I would personally target an adventure movie although not appearing anywhere in these metrics, it tends to have one of the highest percentage success across all movies above 2% of all adventure movies made’\n‘Task 5’\n\nActor_success&lt;- Successful_Movies |&gt;\n        filter(Success_measure &gt;= 10) |&gt;\n        separate_longer_delim(genres, \",\")|&gt;\n        filter(genres == \"Adventure\") |&gt;\n        inner_join(NAME_BASICS |&gt;\n                   separate_longer_delim(primaryProfession, \",\")|&gt;\n                   separate_longer_delim(knownForTitles, \",\")|&gt; \n                   filter(primaryProfession == \"director\"|primaryProfession == \"actor\")|&gt;\n                   select(knownForTitles,primaryName,birthYear,primaryProfession),\n                   join_by(tconst == knownForTitles)) |&gt;\n        group_by(primaryName,primaryProfession,startYear,birthYear) |&gt;\n        summarize(number_of_successful_movies = n(),Number_of_Votes = sum(numVotes,na.rm = FALSE),Average_rating = mean(averageRating)) |&gt;\n        filter(!is.na(birthYear))|&gt;\n        arrange(desc(number_of_successful_movies))\n\n`summarise()` has grouped output by 'primaryName', 'primaryProfession',\n'startYear'. You can override using the `.groups` argument.\n\nkable(Actor_success |&gt;\n        group_by(primaryName,primaryProfession,birthYear) |&gt;\n        summarize(Successes = sum(number_of_successful_movies,na.rm = FALSE))|&gt;\n        arrange(desc(Successes))|&gt;\n        rename(Name = primaryName, Profession = primaryProfession)|&gt;\n        head(100),align = \"l\")\n\n`summarise()` has grouped output by 'primaryName', 'primaryProfession'. You can\noverride using the `.groups` argument.\n\n\n\n\n\nName\nProfession\nbirthYear\nSuccesses\n\n\n\n\n‘Chico’ Hernandez\nactor\n1958\n4\n\n\n‘Chico’ Hernandez\ndirector\n1958\n4\n\n\nAaron Blaise\ndirector\n1968\n4\n\n\nAaron C. Fitzgerald\nactor\n1978\n4\n\n\nAaron Fors\nactor\n1989\n4\n\n\nAaron Kozak\nactor\n1983\n4\n\n\nAdam Austin\nactor\n1965\n4\n\n\nAdam Brown\nactor\n1980\n4\n\n\nAdam J. Ely\nactor\n1979\n4\n\n\nAdam May\ndirector\n1979\n4\n\n\nAdriano Cirulli\ndirector\n1973\n4\n\n\nAidan Turner\nactor\n1983\n4\n\n\nAkihiro Tomikawa\nactor\n1968\n4\n\n\nAkira Kushida\nactor\n1948\n4\n\n\nAl Matthews\nactor\n1942\n4\n\n\nAl Zinnen\nactor\n1903\n4\n\n\nAlan Lee\nactor\n1947\n4\n\n\nAlan Ritchson\nactor\n1982\n4\n\n\nAlan Ritchson\ndirector\n1982\n4\n\n\nAlbert R. Broccoli\nactor\n1909\n4\n\n\nAlbert Uderzo\nactor\n1927\n4\n\n\nAlbert Uderzo\ndirector\n1927\n4\n\n\nAlbie Woodington\nactor\n1952\n4\n\n\nAlec Mills\ndirector\n1932\n4\n\n\nAleksandr Kraevskiy\nactor\n1980\n4\n\n\nAles Kosnar\nactor\n1972\n4\n\n\nAlex Cannon\ndirector\n1977\n4\n\n\nAlex McCormack\nactor\n1985\n4\n\n\nAlfred Enoch\nactor\n1988\n4\n\n\nAllen Jo\nactor\n1977\n4\n\n\nAlvaro Zendejas\ndirector\n1983\n4\n\n\nAmit Soni\nactor\n1982\n4\n\n\nAmy Eglen\ndirector\n1993\n4\n\n\nAmy Johnston\ndirector\n1990\n4\n\n\nAndrew Adamson\ndirector\n1966\n4\n\n\nAndrew Harvey\ndirector\n1981\n4\n\n\nAndrew Jack\nactor\n1944\n4\n\n\nAndrew Lesnie\nactor\n1956\n4\n\n\nAndrew Stanton\nactor\n1965\n4\n\n\nAndrew Tamandl\ndirector\n1968\n4\n\n\nAngelo Ragusa\nactor\n1952\n4\n\n\nAnthony Daniels\nactor\n1946\n4\n\n\nAnthony Russo\ndirector\n1970\n4\n\n\nAntonio Funaro\nactor\n1982\n4\n\n\nAntonio Molina\nactor\n1954\n4\n\n\nAri Ross\ndirector\n1979\n4\n\n\nArnold Vosloo\nactor\n1962\n4\n\n\nArt Stevens\ndirector\n1915\n4\n\n\nArthur Max\nactor\n1946\n4\n\n\nAsher Blinkoff\nactor\n2008\n4\n\n\nAssis Eloy\nactor\n1985\n4\n\n\nAttila Illés\nactor\n1988\n4\n\n\nBarry Blanchard\nactor\n1959\n4\n\n\nBarry R. Koper\nactor\n1955\n4\n\n\nBeau Brasseaux\nactor\n1989\n4\n\n\nBen Collins\nactor\n1975\n4\n\n\nBenedict Wong\nactor\n1970\n4\n\n\nBernard Bresslaw\nactor\n1934\n4\n\n\nBernard Lee\nactor\n1908\n4\n\n\nBill Roberts\ndirector\n1899\n4\n\n\nBill Thompson\nactor\n1913\n4\n\n\nBilly Dee Williams\nactor\n1937\n4\n\n\nBob Anderson\nactor\n1922\n4\n\n\nBob Barlen\ndirector\n1980\n4\n\n\nBob Carlson\ndirector\n1906\n4\n\n\nBob Gale\ndirector\n1951\n4\n\n\nBob Mano\nactor\n1955\n4\n\n\nBob Peterson\nactor\n1961\n4\n\n\nBob Simmons\nactor\n1922\n4\n\n\nBobby Block\nactor\n1991\n4\n\n\nBogdan Draghici\ndirector\n1982\n4\n\n\nBonnie Wright\ndirector\n1991\n4\n\n\nBrad Abrell\nactor\n1965\n4\n\n\nBrad Heiner\nactor\n1964\n4\n\n\nBrad Jeffries\nactor\n1960\n4\n\n\nBradley Everett Wilson\ndirector\n1980\n4\n\n\nBrent Spiner\nactor\n1949\n4\n\n\nBrent Spiner\ndirector\n1949\n4\n\n\nBrian Goldner\nactor\n1963\n4\n\n\nBrian M. Rosen\nactor\n1971\n4\n\n\nBrian Magner\nactor\n1978\n4\n\n\nBrian Mainolfi\ndirector\n1971\n4\n\n\nBrock Little\nactor\n1967\n4\n\n\nBruno Mars\nactor\n1985\n4\n\n\nBryan Adams\nactor\n1959\n4\n\n\nBryon Weiss\nactor\n1963\n4\n\n\nBryon Weiss\ndirector\n1963\n4\n\n\nC. Andrew Nelson\nactor\n1962\n4\n\n\nCal Brunker\ndirector\n1978\n4\n\n\nCan Bolat\nactor\n1998\n4\n\n\nCarlos Saldanha\ndirector\n1965\n4\n\n\nChad Sellers\nactor\n1982\n4\n\n\nCharles Haugk\nactor\n1953\n4\n\n\nChris Antonini\nactor\n1977\n4\n\n\nChris Buck\ndirector\n1958\n4\n\n\nChris Cason\nactor\n1974\n4\n\n\nChris Clarke\nactor\n1977\n4\n\n\nChris Cossey\nactor\n1984\n4\n\n\nChris Daniels\nactor\n1976\n4\n\n\nChris Dawson\nactor\n1965\n4\n\n\n\n\nkable(Actor_success |&gt;\n        group_by(primaryName,primaryProfession,birthYear) |&gt;\n        summarize(Successes = sum(number_of_successful_movies,na.rm = FALSE))|&gt;\n        filter(birthYear &gt;= 1990) |&gt;\n        arrange(desc(Successes))|&gt;\n        rename(Name = primaryName, Profession = primaryProfession)|&gt;\n        head(100),align = \"l\")\n\n`summarise()` has grouped output by 'primaryName', 'primaryProfession'. You can\noverride using the `.groups` argument.\n\n\n\n\n\nName\nProfession\nbirthYear\nSuccesses\n\n\n\n\nAmy Eglen\ndirector\n1993\n4\n\n\nAmy Johnston\ndirector\n1990\n4\n\n\nAsher Blinkoff\nactor\n2008\n4\n\n\nBobby Block\nactor\n1991\n4\n\n\nBonnie Wright\ndirector\n1991\n4\n\n\nCan Bolat\nactor\n1998\n4\n\n\nDaniel Pentkowski\nactor\n1991\n4\n\n\nDavid De Juan\ndirector\n1990\n4\n\n\nElliott Cattell\ndirector\n1991\n4\n\n\nGeorge Redstone\ndirector\n2000\n4\n\n\nIvan Sorgente\nactor\n1993\n4\n\n\nJackey Mishra\nactor\n1998\n4\n\n\nJacob Batalon\nactor\n1996\n4\n\n\nJohn Boyega\nactor\n1992\n4\n\n\nJosh Hutcherson\nactor\n1992\n4\n\n\nJosh Hutcherson\ndirector\n1992\n4\n\n\nKanata Hongô\nactor\n1990\n4\n\n\nLiam Hemsworth\nactor\n1990\n4\n\n\nLuke Scott\nactor\n1994\n4\n\n\nMathew Yanagiya\nactor\n1990\n4\n\n\nRicky Arietta\ndirector\n1991\n4\n\n\nShu Watanabe\nactor\n1991\n4\n\n\nSôta Fukushi\nactor\n1993\n4\n\n\nTrey Brown\nactor\n1993\n4\n\n\nViolet Columbus\ndirector\n1994\n4\n\n\nWilliam Melling\nactor\n1994\n4\n\n\nAaron Dismuke\nactor\n1992\n3\n\n\nAjay Lobo\nactor\n1997\n3\n\n\nAleks Le\nactor\n1999\n3\n\n\nAlex R. Wagner\ndirector\n1991\n3\n\n\nAlexander Canton\nactor\n1995\n3\n\n\nAmaan Shaikh\nactor\n2000\n3\n\n\nAnastasia Zabarchuk\ndirector\n1997\n3\n\n\nArchie Renaux\nactor\n1997\n3\n\n\nArvind Kashyap\nactor\n1992\n3\n\n\nBart the Bear\nactor\n2000\n3\n\n\nBehnam Taheri\ndirector\n1990\n3\n\n\nBilly Jackson\nactor\n1995\n3\n\n\nBooboo Stewart\nactor\n1994\n3\n\n\nBrayden Patterson\nactor\n1992\n3\n\n\nChandler Frantz\nactor\n1998\n3\n\n\nChristopher Painter\nactor\n1992\n3\n\n\nCody Simpson\nactor\n1997\n3\n\n\nCody Simpson\ndirector\n1997\n3\n\n\nCooper Cowgill\nactor\n1995\n3\n\n\nDaryl Sabara\nactor\n1992\n3\n\n\nDavide Anselmi\ndirector\n1999\n3\n\n\nDonte Paris\nactor\n1998\n3\n\n\nEdouard Calemard\ndirector\n1992\n3\n\n\nElan Garfias\nactor\n1999\n3\n\n\nElias Mlayeh\nactor\n1991\n3\n\n\nFinneas O’Connell\nactor\n1997\n3\n\n\nGeorgie Henley\ndirector\n1995\n3\n\n\nGianni Biasetti Jr.\nactor\n1992\n3\n\n\nHarry Holland\nactor\n1999\n3\n\n\nHarry Holland\ndirector\n1999\n3\n\n\nHayato Onozuka\nactor\n1993\n3\n\n\nIan Chen\nactor\n2006\n3\n\n\nIzaac Wang\nactor\n2007\n3\n\n\nJack Millar\ndirector\n1991\n3\n\n\nJacob Bertrand\nactor\n2000\n3\n\n\nJacob Bertrand\ndirector\n2000\n3\n\n\nJacob Lofland\nactor\n1996\n3\n\n\nJacob Smith\nactor\n1990\n3\n\n\nJake Cherry\nactor\n1996\n3\n\n\nJohn Bell\nactor\n1997\n3\n\n\nJordan Fry\nactor\n1993\n3\n\n\nJoshua R. Jones\nactor\n1990\n3\n\n\nJustice Smith\nactor\n1995\n3\n\n\nKai Lydgate\nactor\n1992\n3\n\n\nKhaled Elkodosy\nactor\n2001\n3\n\n\nKristen Stewart\ndirector\n1990\n3\n\n\nLance Breakwell\nactor\n1993\n3\n\n\nMarvin Jaacks\nactor\n1996\n3\n\n\nMax Charles\nactor\n2003\n3\n\n\nMelody Wayfare\ndirector\n1994\n3\n\n\nMichaela Jill Murphy\ndirector\n1994\n3\n\n\nMustard\nactor\n1990\n3\n\n\nNaomi Scott\ndirector\n1993\n3\n\n\nNathan Velasquez\nactor\n1996\n3\n\n\nNiall Horn\ndirector\n1997\n3\n\n\nNicholas Bird\nactor\n1994\n3\n\n\nNikita Hopkins\nactor\n1991\n3\n\n\nOmar Fathy Saber\nactor\n1998\n3\n\n\nPeregrine Kitchener-Fellowes\nactor\n1991\n3\n\n\nPeter Varnai\ndirector\n1991\n3\n\n\nReed Buck\nactor\n1994\n3\n\n\nRofique Khan\nactor\n1997\n3\n\n\nRoss Simanteris\nactor\n1994\n3\n\n\nRyan Cunningham\ndirector\n1990\n3\n\n\nRyunosuke Kamiki\nactor\n1993\n3\n\n\nRyô Yoshizawa\nactor\n1994\n3\n\n\nScotty Cook\nactor\n1991\n3\n\n\nShameik Moore\nactor\n1995\n3\n\n\nShane Baumel\nactor\n1997\n3\n\n\nShôma Kai\nactor\n1997\n3\n\n\nSkandar Keynes\nactor\n1991\n3\n\n\nSo Okuno\nactor\n2000\n3\n\n\nSwae Lee\nactor\n1993\n3\n\n\nTake That\nactor\n1990\n3\n\n\n\n\n\nI will select James Cameron as the director given his experience in the industry and successful performance and Orlando Bloom who had successes in Lord of the rings and Liam Hemsworth who has had vast experience in the industry and an already created persona.\n\nggplot(Actor_success |&gt;\n                 mutate(Decade = floor(startYear/10)*10) |&gt;\n                 group_by(Decade,primaryName) |&gt;\n                 filter(primaryName == \"James Cameron\"|primaryName == \"Orlando Bloom\"|primaryName == \"Liam Hemsworth\") |&gt;\n                 summarize(Number_of_Votes = mean(Number_of_Votes))\n               , aes(x = Decade, y = Number_of_Votes,group = primaryName,colour = primaryName)) +\n          geom_bar(stat=\"Identity\") +\n          labs(title = \"Number of Adventure Movies by Decade\") +\n          xlab(\"Year\") +\n          ylab(\"Number of Votes\") +\n          scale_x_continuous(breaks = seq(1920, 2020, by = 10), labels = paste0(seq(1920, 2020, by = 10), \"s\")) +\n          ggtitle(label = \"Number of Advenutre movies votes by Year\")\n\n`summarise()` has grouped output by 'Decade'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nNow is the perfect time for you three to team up and make an attempt to recapture the nostalgic market, during your peak times 2000s and 2010s, you were very successful particularly in the adventure category and have all had exposure to the movie category. The decline in votes is common across the industry and is waiting for a revival, similar to what you did back in 2000s.\n\nggplot(TITLE_RATINGS|&gt;\n                  inner_join(TITLE_BASICS |&gt;\n                               separate_longer_delim(genres, \",\")|&gt;\n                               filter(genres == \"Adventure\") |&gt;\n                               filter(titleType == \"movie\") |&gt;\n                               select(tconst,startYear),join_by(tconst == tconst)) |&gt;\n                  mutate(Decade = floor(startYear/10)*10) |&gt;\n                  group_by(Decade) |&gt;\n                  summarize(Number_of_Votes = mean(numVotes))\n                , aes(x = Decade, y = Number_of_Votes)) +\n           geom_line() +\n           labs(title = \"Number of Adventure Movies by Decade\") +\n           xlab(\"Year\") +\n           ylab(\"Number of Votes\") +\n           scale_x_continuous(breaks = seq(1920, 2020, by = 10), labels = paste0(seq(1920, 2020, by = 10), \"s\")) +\n           ggtitle(label = \"Number of Advenutre movies votes by Year\")\n\n\n\n\n\n\n\n\nTask 6\n\nkable(TITLE_RATINGS|&gt;\n  inner_join(TITLE_BASICS |&gt;\n               separate_longer_delim(genres, \",\")|&gt;\n               filter(genres == \"Adventure\") |&gt;\n               filter(titleType == \"movie\") |&gt;\n               select(tconst,startYear,primaryTitle),join_by(tconst == tconst)) |&gt;\n    filter(numVotes&gt;=100000) |&gt;\n    filter(startYear &lt;= 1999) |&gt;\n    filter(startYear &gt;= 1985) |&gt;\n    select(-tconst) |&gt;\n    filter(averageRating &gt;=7.0) |&gt;\n    rename(Rating = averageRating, 'Number of votes' = numVotes, Title = primaryTitle, Year = startYear,'Success measure'=Success_measure),align = \"l\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nRating\nNumber of votes\nSuccess measure\nYear\nTitle\n\n\n\n\n8.5\n1338094\n15\n1985\nBack to the Future\n\n\n7.7\n304938\n14\n1985\nThe Goonies\n\n\n8.4\n787933\n14\n1986\nAliens\n\n\n7.2\n157263\n13\n1986\nBig Trouble in Little China\n\n\n7.0\n150140\n13\n1986\nHighlander\n\n\n7.3\n153326\n13\n1986\nLabyrinth\n\n\n8.1\n451763\n14\n1986\nStand by Me\n\n\n8.0\n186529\n14\n1986\nCastle in the Sky\n\n\n7.8\n466089\n14\n1987\nPredator\n\n\n8.0\n457779\n14\n1987\nThe Princess Bride\n\n\n7.1\n211171\n13\n1987\nSpaceballs\n\n\n7.4\n100905\n13\n1988\nThe Land Before Time\n\n\n7.7\n220879\n14\n1988\nWho Framed Roger Rabbit\n\n\n7.2\n131613\n13\n1988\nWillow\n\n\n7.5\n197562\n14\n1989\nThe Abyss\n\n\n7.8\n584607\n14\n1989\nBack to the Future Part II\n\n\n7.5\n412097\n14\n1989\nBatman\n\n\n8.2\n822658\n14\n1989\nIndiana Jones and the Last Crusade\n\n\n7.6\n295670\n14\n1989\nThe Little Mermaid\n\n\n7.4\n490163\n13\n1990\nBack to the Future Part III\n\n\n8.0\n296111\n14\n1990\nDances with Wolves\n\n\n7.5\n218647\n14\n1990\nThe Hunt for Red October\n\n\n7.5\n360557\n14\n1990\nTotal Recall\n\n\n8.6\n1198743\n16\n1991\nTerminator 2: Judgment Day\n\n\n7.6\n177729\n14\n1991\nThelma & Louise\n\n\n8.0\n477950\n14\n1992\nAladdin\n\n\n7.7\n105517\n14\n1992\nPorco Rosso\n\n\n7.6\n192146\n14\n1992\nThe Last of the Mohicans\n\n\n7.0\n115846\n13\n1993\nCool Runnings\n\n\n8.2\n1089950\n15\n1993\nJurassic Park\n\n\n8.5\n1167510\n15\n1994\nThe Lion King\n\n\n7.0\n120889\n13\n1994\nMaverick\n\n\n7.3\n399613\n13\n1994\nSpeed\n\n\n7.0\n208702\n13\n1994\nStargate\n\n\n7.7\n320610\n14\n1995\nApollo 13\n\n\n7.5\n104440\n14\n1995\nDead Man\n\n\n7.6\n413328\n14\n1995\nDie Hard with a Vengeance\n\n\n7.2\n273448\n13\n1995\nGoldenEye\n\n\n7.1\n385728\n13\n1995\nJumanji\n\n\n8.3\n1091017\n15\n1995\nToy Story\n\n\n7.0\n616988\n13\n1996\nIndependence Day\n\n\n7.2\n478320\n13\n1996\nMission: Impossible\n\n\n7.4\n363692\n13\n1996\nThe Rock\n\n\n7.6\n133508\n14\n1996\nStar Trek: First Contact\n\n\n7.1\n138489\n13\n1997\nAnastasia\n\n\n7.0\n261389\n13\n1997\nAustin Powers: International Man of Mystery\n\n\n7.6\n516157\n14\n1997\nThe Fifth Element\n\n\n7.3\n260900\n13\n1997\nHercules\n\n\n7.3\n625000\n13\n1997\nMen in Black\n\n\n8.3\n444748\n14\n1997\nPrincess Mononoke\n\n\n7.1\n158630\n13\n1997\nSeven Years in Tibet\n\n\n7.1\n182406\n13\n1999\nThree Kings\n\n\n7.3\n328112\n13\n1997\nStarship Troopers\n\n\n7.9\n631324\n14\n1999\nToy Story 2\n\n\n7.1\n471238\n13\n1999\nThe Mummy\n\n\n7.2\n320135\n13\n1998\nA Bug’s Life\n\n\n7.3\n231450\n13\n1999\nDogma\n\n\n7.5\n305740\n14\n1998\nFear and Loathing in Las Vegas\n\n\n7.7\n323586\n14\n1998\nMulan\n\n\n7.2\n149896\n13\n1998\nThe Prince of Egypt\n\n\n7.3\n252688\n13\n1999\nTarzan\n\n\n8.1\n234826\n14\n1999\nThe Iron Giant\n\n\n7.4\n181820\n13\n1999\nGalaxy Quest\n\n\n\n\n\nThe Movie I have selected to recreate would be to produce a Dead Man sequel, with anew cast however I think would be interesting for Jim Jarmusch as the original director to provide his creative feedback, and insight and Johnny Depp as the primary actor from the original to provide consultative services on it.\nTask 7\n’Pitch:\nWhy This Project?\n\nReviving a Classic: Dead Man remains a cult classic, and a sequel would tap into a passionate fanbase.\nProven Talent: Orlando Bloom iconic performance and James Camerons visionary directing skills aswell as longevity being successful across decades offer a strong foundation. Particularly during the 2000’s around when Dead Man first released.\nRising Star: Liam Hemsworth, a proven action star, adds a contemporary appeal. Adventure Renaissance:\nAdventure films have enjoyed a resurgence and growth in popularity up around 200-500% over the past 30-40 years, with audiences craving escapism and thrilling narratives.\nNostalgia and Innovation: The film can blend nostalgia for the original with modern storytelling techniques, creating a fresh and exciting experience.’\n\nClassic 90’s style teaser\nFrom director James Cameron, the visionary mind behind Avatar; and From actor Orlando Bloom, beloved star of Lord of the Rings; and From Liam Hemsworth, Hollywood icon of Adventure, Comes the timeless tail Dead Mans Return A story of Legacy and Redemption, The Changing West, and The Power of Friendship Coming soon to a theater near you."
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Will Peters STA9750-2024-FALL MP03",
    "section": "",
    "text": "Given that the election just happened, I thought I might take the opportunity to learn the results of previous elections, particularly as an Australian, I can admit the U.S Electoral College System is confusing\nSo to start off with, installing all the libraries that I used at some point in this project, hidden out of convenience so it can flow easier."
  },
  {
    "objectID": "mp03.html#us-election-votes",
    "href": "mp03.html#us-election-votes",
    "title": "Will Peters STA9750-2024-FALL MP03",
    "section": "US Election Votes",
    "text": "US Election Votes\nTo start off with, we need to download and extract the votes for state-wide presidential and house level votes, here is where I add a note that the incomplete data, means you will need to add in District of Columbia (D.C), did you know that is what D.C stood for? At least when it comes the states not to be confused with Detective Comics for DC Comics.\nI have included the sources for the president and house votes, in case you want to follow along.\nPresident votes\nHouse votes\n\nPresident_votes &lt;- as.data.frame(readr::read_csv(\"1976-2020-president.csv\", lazy=FALSE)) \n# As you can see I called the presidents file 1976-2020-president.csv for simplicity#\n\nHouse_votes &lt;- as.data.frame(readr::read_csv(\"1976-2022-house.csv\", lazy=FALSE)) \n# As you can see I called the house votes file 1976-2020-house.csv for simplicity#\n\nAs I mentioned earlier we need to add in the D.C. votes for each year, otherwise we will have incomplete data, in this case Democrats have won each year in our time period all 3 seats except 2000 where they won 2 out of 3, and as such going to be allocating all seats in all elections to the Democrats.\n\n#Extracting all the years that D.C appeared in the data#\nexisting_dc_years &lt;- House_votes |&gt;\n  filter(state == \"DISTRICT OF COLUMBIA\") |&gt;\n  pull(year) |&gt;\n  unique()\n\n#Calculating all the available years#\nall_years &lt;- unique(House_votes$year)\n#Comparing missing years of D.C to wider population#\nmissing_dc_years &lt;- setdiff(all_years, existing_dc_years)\n\n#populating the data frame for house votes, with some filler D.C information#\ndc_entries &lt;- data.frame(\n  year = missing_dc_years,\n  state = \"DISTRICT OF COLUMBIA\",\n  state_po = NA,\n  state_fips = NA,\n  state_cen = NA,\n  state_ic = NA,\n  office = \"US HOUSE\",\n  district = 0,\n  stage = \"SPECIAL\",\n  runoff = NA,\n  special = NA,\n  candidate = \"D.C.\",\n  party = \"DEMOCRAT\",\n  writein = NA,\n  mode = NA,\n  candidatevotes = 1,\n  totalvotes = 1,\n  unofficial = NA,\n  version = NA,\n  fusion_ticket = NA)\n\n#Combining the missing D.C votes with the wider House_votes population# \nHouse_votes &lt;- rbind(House_votes, dc_entries)"
  },
  {
    "objectID": "mp03.html#congressional-boundaries",
    "href": "mp03.html#congressional-boundaries",
    "title": "Will Peters STA9750-2024-FALL MP03",
    "section": "Congressional Boundaries",
    "text": "Congressional Boundaries\nSo to prepare for the Congressional Boundaries and the wider geo-spatial mapping, I did have to cheat a little bit, and copy and paste the table in the download period to extract the dates. So you will see the read_csv rather than an html extract given the table_wrapper used for the data. If you have figured that out well done, and reachout on my github as you can color me impressed.\n\n#Starts off with the file for the District mapping# \nDistrict_Mapping &lt;- as.data.frame(readr::read_csv(\"District Mapping.csv\", lazy=FALSE)) |&gt;\n  # Extract years from using regex\n  mutate(Start_Year = as.numeric(str_extract(Period, \"\\\\d{4}\")),\n         End_Year = as.numeric(str_extract(str_sub(Period, -4), \"\\\\d{4}\"))) |&gt;\n  # Create a list-column with sequences of years between two years so if 1803-1805 will create a nested list of 1803,1804,1805 to capture the entire period#\n  rowwise() |&gt;\n  mutate(Year = list(Start_Year:End_Year)) |&gt;\n  # Expand each row for each year in the list#\n  unnest(Year) |&gt;\n  # Select only the relevant columns#\n  select(District_file = `District file`, District_Number = `District Number`, Year) |&gt;\n  mutate(District_Number = str_sub(District_Number,end = -3)) |&gt;\n  #Treating the District as a 3 character string with \"0\" added for any 1,2 digit districts#\n  mutate(District_Number = as.character(sprintf(\"%03d\",as.numeric(District_Number))))\n\nIf you are following along so far, I thought it might be helpful for a small gift of a table to be shown of how we are treating the District table that we will be using in the mapping.\n\nkable(District_Mapping |&gt;\n        tail(10))\n\n\n\n\nDistrict_file\nDistrict_Number\nYear\n\n\n\n\ndistricts111.zip\n111\n2009\n\n\ndistricts111.zip\n111\n2010\n\n\ndistricts112.zip\n112\n2011\n\n\ndistricts112.zip\n112\n2012\n\n\ndistricts112.zip\n112\n2013\n\n\ndistricts113.zip\n113\n2013\n\n\ndistricts113.zip\n113\n2014\n\n\ndistricts114.zip\n114\n2015\n\n\ndistricts114.zip\n114\n2016\n\n\ndistricts114.zip\n114\n2017\n\n\n\n\n\n\nDownloading Congressional Zips\nThis is where we start utilize the automated downloading of the ZIP files, which include the sections of different districts used in the election and the spatial analysis of them, thank you to Jefferey Lewis, who put this together, as creating from scratch the spatial analysis of Congressional Districts would be a real challenge. Given that it is 2 separate websites, one for 1976-2014 that we are analyzing and a separate one for 2014-2022 which is the latest direct information from the government I am going to coin these two as Tasks 1 (Shape Files from 1976-2012) and Task 2 (Shape Files from 2014-2022)\n\nTask 1\n\n#Start off with the base URL#\nurl_base &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\n#For the congressional boundaries and to be respectful, only utilizing districts 94-112 which covers 1976-2014\nnumbers_for_congress &lt;- sprintf(\"%03d\", 94:112)\n\n#Creating a function to download and read the district zip file\ndownload_and_read_district &lt;- function(number) {\n\n    # Define the base URL and construct the full URL and destination file name#\n    url_base &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\n    #combining the url used to extract from the web#\n    file_url &lt;- paste0(url_base, \"districts\", number, \".zip\")\n    #telling it where to store the Congressional district data output# \n    dest_file &lt;- paste0(\"districts\", number, \".zip\")\n    \n    # Check if the file already exists before downloading#\n    if (!file.exists(dest_file)) {\n      download.file(file_url, destfile = dest_file)\n      cat(\"Downloaded:\", dest_file, \"\\n\")\n    } else {\n      cat(\"File already exists:\", dest_file, \"\\n\")\n    }\n}\n#Well done in following along the creation of the function#\n\n#now going through a loop and running for each number in numbers for congress defined above applying it to download onto the local drive the districts Zip file#\nfor(number in numbers_for_congress) {\n  download_and_read_district(number)\n}\n\nFile already exists: districts094.zip \nFile already exists: districts095.zip \nFile already exists: districts096.zip \nFile already exists: districts097.zip \nFile already exists: districts098.zip \nFile already exists: districts099.zip \nFile already exists: districts100.zip \nFile already exists: districts101.zip \nFile already exists: districts102.zip \nFile already exists: districts103.zip \nFile already exists: districts104.zip \nFile already exists: districts105.zip \nFile already exists: districts106.zip \nFile already exists: districts107.zip \nFile already exists: districts108.zip \nFile already exists: districts109.zip \nFile already exists: districts110.zip \nFile already exists: districts111.zip \nFile already exists: districts112.zip \n\n\nWell done we have now downloaded all the relevant zip files that we will be needing from this source, these will later come in handy but for early stages, we can keep these in storage.\n\n\nTask 2\nDownloading the information for 2014-2022 from the government website directly, this will be useful as more and more information is stored, but half the role is always aggregating the data and ensuring data quality.\n\n#Website for 2014-2022 data on the census.gov link, to be later shown#\nurl_base_2 &lt;- \"https://www2.census.gov/geo/tiger\"\n#years for census source of data#\nnumbers_for_census &lt;-  sprintf(\"%04d\",2014:2022)\n\n#creation of tiger data to be downloaded#\n  download_and_read_tiger &lt;- function(number) {\n    numeric_year &lt;- as.numeric(number)\n    # Define the base URL and construct the full URL and destination file name\n    cd_desc &lt;- ifelse(numeric_year &gt;= 2018,\"116\",\n                      ifelse(numeric_year &gt;= 2016,\"115\",\"114\"))\n    #used because the ending cd was not consistent, could use a wild card or number here\n    file_url &lt;- paste0(url_base_2, \"/TIGER\", numeric_year,\"/CD/tl_\",numeric_year,\"_us_cd\",cd_desc,\".zip\")\n    #generates file url#\n    dest_file &lt;- paste0(\"Tiger\", numeric_year, \".zip\")\n    \n    # Check if the file already exists before downloading\n    if (!file.exists(dest_file)) {\n      download.file(file_url, destfile = dest_file)\n      cat(\"Downloaded:\", dest_file, \"\\n\")\n    } else {\n      cat(\"File already exists:\", dest_file, \"\\n\")\n    }\n  }\n  \n  #same as before loops through each number in census to run the function#\n  for(number in numbers_for_census) {\n    download_and_read_tiger(number)\n  }\n\nFile already exists: Tiger2014.zip \nFile already exists: Tiger2015.zip \nFile already exists: Tiger2016.zip \nFile already exists: Tiger2017.zip \nFile already exists: Tiger2018.zip \nFile already exists: Tiger2019.zip \nFile already exists: Tiger2020.zip \nFile already exists: Tiger2021.zip \nFile already exists: Tiger2022.zip \n\n\nI appreciate your patience to get to this stage, but as you can imagine there is a lot of Data preparation before we get to the stage of demonstrating and visualizing the data."
  },
  {
    "objectID": "mp03.html#preliminary-analysis-of-vote-count-data",
    "href": "mp03.html#preliminary-analysis-of-vote-count-data",
    "title": "Will Peters STA9750-2024-FALL MP03",
    "section": "Preliminary analysis of Vote Count Data",
    "text": "Preliminary analysis of Vote Count Data\nSo now we get to the stage where we can Explore the Vote Count Data, if you consider this our third task of automating the process. We are going to be investigating just on the House of Representatives and seeing which states have gained or lost power over the past 46 years (1976-2022). Interestingly as a basketball fan 1976 was when the NBA and ABA merged, obviously not being born I have only heard stories about this.\n\nTask 3\nSo to start it off we want to see what the change in the number of house votes were, or who gained and lost the most power.\n\n#Remember House_votes is where we pulled in the csv file, if you are following along#\nChanges_in_house &lt;- House_votes |&gt;\n  group_by(year, state_po) |&gt;\n  summarise(max_year_state = max(district, na.rm = TRUE)) |&gt;\n  arrange(year, desc(max_year_state), state_po) |&gt;\n  mutate(max_year_state = ifelse(max_year_state == 0,1, max_year_state))\n#not going to go into too much detail but essentially if there is more than one district the max number for a district, will be how many districts that state had, if it only had one that the district would be 0, so including an ifelse to turn that 0 into a 1.\n\n`1976_2022_Change` &lt;- Changes_in_house |&gt;\n  filter (year %in%  c(1976,2022)) |&gt;\n  pivot_wider (\n    names_from = year,\n    values_from = max_year_state\n) |&gt;\n  mutate (`change` = `2022` - `1976`) |&gt;\n  arrange(`change`)\n#For this table, we are only keeping the start and end 1976 - 2022 and calculating the difference#\n\nkable(\n        bind_rows(\n          `1976_2022_Change` |&gt; slice_max(`change`, n = 1),   # Top result based on 2021 values\n          `1976_2022_Change` |&gt; slice_min(`change`, n = 1)    # Bottom result based on 2021 values\n        )\n)#joining the top and bottom results of who has won and lost the most\n\n\n\n\nstate_po\n1976\n2022\nchange\n\n\n\n\nTX\n24\n38\n14\n\n\nNY\n39\n26\n-13\n\n\n\n\n\nSo that is fascinating that New York has lost the most states and Texas has gained the most, now each person has there own theories, my reason would be Covid made a lot of jobs remote, and so New York lost it’s charm compared to pre-Covid times, whereas Texas and Florida were a lot more open so drew people to the freedom.\nNow who here knew about fusion voting which is candidates appearing multiple times on the ballot under multiple parties, such as Michael Zumbluskas who appeared in Republican, Conservative and Parent. This is something I had to get my head around, but thankfully only applies to New York and Connecticut.\n\nWinner_by_Unique_party &lt;- House_votes |&gt;\n  group_by(year, state_po,district) |&gt;\n  slice_max(candidatevotes, n=1, with_ties = FALSE) |&gt;\n  ungroup()\n#Calculating who would win, by the candidate votes directly, hence why no grouping by candidate\n\nWinner_by_Individual &lt;- House_votes |&gt;\n  group_by(year, state_po,district, candidate) |&gt;\n  summarise(candidatevotes = sum(candidatevotes)) |&gt;\n  group_by(year, state_po,district) |&gt;\n  slice_max(candidatevotes, n=1, with_ties = FALSE) |&gt;\n  ungroup()\n#As you can see grouping by candidate this time to aggregate across all parties. \n\nFusion_advantage &lt;- Winner_by_Individual |&gt;\n  left_join(Winner_by_Unique_party, by = c(\"year\",\"state_po\",\"district\",\"candidate\")) |&gt;\n  filter(is.na(office)) |&gt;\n  select(year,state_po,district,candidate)\n#Comparing where the individual Won due to the voting structure rather than the way it occurs in other states#\n\nkable(Fusion_advantage)\n\n\n\n\nyear\nstate_po\ndistrict\ncandidate\n\n\n\n\n1976\nNY\n29\nEDWARD W PATTISON\n\n\n1980\nNY\n3\nGREGORY W CARMAN\n\n\n1980\nNY\n6\nJOHN LEBOUTILLIER\n\n\n1984\nNY\n20\nJOSEPH J DIOGUARDI\n\n\n1986\nNY\n27\nGEORGE C WORTLEY\n\n\n1992\nCT\n2\nSAM GEJDENSON\n\n\n1992\nNY\n3\nPETER T KING\n\n\n1994\nNY\n1\nMICHAEL P FORBES\n\n\n1996\nNY\n1\nMICHAEL P FORBES\n\n\n1996\nNY\n30\nJACK QUINN\n\n\n1996\nTX\n9\nNICK LAMPSON\n\n\n2000\nCT\n2\nROB SIMMONS\n\n\n2006\nNY\n25\nJAMES T WALSH\n\n\n2006\nNY\n29\nJOHN R “RANDY” KUHL JR\n\n\n2010\nNY\n13\nMICHAEL G GRIMM\n\n\n2010\nNY\n19\nNAN HAYMORTH\n\n\n2010\nNY\n24\nRICHARD L HANNA\n\n\n2010\nNY\n25\nANN MARIE BUERKLE\n\n\n2012\nNY\n27\nCHRIS COLLINS\n\n\n2018\nNY\n1\nLEE M ZELDIN\n\n\n2018\nNY\n24\nJOHN M KATKO\n\n\n2018\nNY\n27\nCHRIS COLLINS\n\n\n2022\nNY\n4\nANTHONY P D’ESPOSITO\n\n\n2022\nNY\n17\nMICHAEL V LAWLER\n\n\n2022\nNY\n22\nBRANDON M WILLIAMS\n\n\n\n\n\nThe Texas examples here are due to the special election, still sorting out how those should be treated going forward, of course I could manually patch those out but I deem that to be unfair, and an inconsistent approach to data, as if it breaks it needs to be fixed.\nFinally I wanted to look into a larger topic, that the president is elected not by the house constituents (granted my knowledge is limited on this) but the district votes are for the house of representatives and president is at a state wide level.\nSo to start with we will prepare the data by reviewing if the Party or the President got more votes state by state.\n\nVotes_Pres_vs_House &lt;- President_votes |&gt;\n  #Starting off with the number of votes for the president#\n  group_by(year,state_po,party_simplified) |&gt;\n  summarise(candidatevotes = sum(candidatevotes)) |&gt;\n  #grouping by year, state and party and calculating how many votes did the president get#\n   inner_join(House_votes |&gt;\n               group_by(year,state_po,party) |&gt;\n               summarise(house_votes = sum(candidatevotes)), by = c(\"year\",\"state_po\",\"party_simplified\"=\"party\")) |&gt;\n  #calculating how many votes the party got at a state level#\n  mutate (Winner = ifelse(candidatevotes&gt;=house_votes,\"Candidate_favorable\",\"House_favorable\"))\n#Calculating if the candidate or the house was favorable\n\nyearly_summary &lt;- Votes_Pres_vs_House |&gt;\n  group_by(year, Winner) |&gt;\n  summarize(count = n()) |&gt;\n  ungroup()\n#Preparing the data in aggregate for candidate vs house favorable#\n\nyearly_summary_Rep &lt;- Votes_Pres_vs_House |&gt;\n  filter(party_simplified == \"REPUBLICAN\") |&gt;\n  group_by(year, Winner) |&gt;\n  summarize(count = n()) |&gt;\n  ungroup()\n#applying above logic for just Republicans#\n\nyearly_summary_Dem &lt;- Votes_Pres_vs_House |&gt;\n  filter(party_simplified == \"DEMOCRAT\") |&gt;\n  group_by(year, Winner) |&gt;\n  summarize(count = n()) |&gt;\n  ungroup()\n#applying above logic for just Democrats#\n\nAfter all that work in preparing the data tables, it comes down to how is it shown in the graphs, the visuals\n\nggplot(yearly_summary, aes(x = year, y = count, color = Winner)) +\n  geom_line(size = 1) +\n  geom_point() +\n  labs(title = \"Year-over-Year Comparison of Candidate vs House Favorable\",\n       x = \"Year\",\n       y = \"Count\",\n       color = \"Preference\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAs you can see this shows that the candidate is generally favorable but there are occasions where the House favor-ability is much higher\n\nggplot(yearly_summary_Rep, aes(x = year, y = count, color = Winner)) +\n  geom_line(size = 1) +\n  geom_point() +\n  labs(title = \"Year-over-Year Comparison of Candidate vs House Favorable\",\n       x = \"Year\",\n       y = \"Count\",\n       color = \"Preference\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nA lot more noticeable in variance until we see in 2020 where they almost perfectly align.\n\nggplot(yearly_summary_Dem, aes(x = year, y = count, color = Winner)) +\n  geom_line(size = 1) +\n  geom_point() +\n  labs(title = \"Year-over-Year Comparison of Candidate vs House Favorable\",\n       x = \"Year\",\n       y = \"Count\",\n       color = \"Preference\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIn more recent years we are seeing the democratic Candidate is preferred over the house_favorable numbers.\nWhat are the takeaways for this it could be due to no simple party identifiers in the house data, or people like to hedge the bets voting one way for president and the other for house."
  },
  {
    "objectID": "mp03.html#extracting-zip-file-information",
    "href": "mp03.html#extracting-zip-file-information",
    "title": "Will Peters STA9750-2024-FALL MP03",
    "section": "Extracting ZIP file information",
    "text": "Extracting ZIP file information\n\nTask 4\n\nread_shp_from_zip &lt;- function(number) {\ntemp_dir &lt;- tempdir()\nzip_contents &lt;- unzip(paste0(\"districts\", number, \".zip\"), \n                      exdir = temp_dir)\nfname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\ndistricts &lt;- read_sf(fname_shp)\ndistricts\n}\n#so this creates the function read_shp_from_zip file with naming convention districts###.ZIP, note this is how we initially automatically pulled in all the information.\n\n\n\nfor (number in numbers_for_congress) {\n  joined_data &lt;- inner_join(District_Mapping,\n    data.frame(District_Number = number),\n   by = \"District_Number\")\n  year &lt;- joined_data$Year\n  districts &lt;- read_shp_from_zip(number)\n  for (year in joined_data$Year) {\n   variable_name &lt;- paste0(\"districts\",year)\n  assign(variable_name,districts)\n}\n}\n#note here is that we are not only running through the extraction of the districts but we are also converting it from district_id to districtyear i.e. will show as district2008\n\nUnique_state &lt;- districts2013 |&gt;\n  mutate(ID = substring(ID, 0, 3)) |&gt;\n  group_by(ID, STATENAME) |&gt;\n  select(ID, STATENAME) |&gt;\n as.data.frame() |&gt;\n  select(-geometry) |&gt;\n  mutate(STATENAME = toupper(STATENAME)) |&gt;\n unique()\n#Maybe an overdoing of the code but this is for future alignment, as in 2014-2022 the ID was used but no state was referenced, and so looping in the statename. #\n\n\nread_shp_from_zip_2 &lt;- function(year) {\n  temp_dir &lt;- tempdir()\n zip_contents &lt;- unzip(paste0(\"Tiger\", year, \".zip\"), \n                        exdir = temp_dir)\n  fname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\n districts &lt;- read_sf(fname_shp)\n  districts\n}\n#Secondly reading in of Tiger files 2014-2022\n\nCD_Years_available &lt;- 2014:2022\n\nfor (year in CD_Years_available) {\n  variable_name &lt;- paste0(\"districts\",year)\n  districts &lt;- read_shp_from_zip_2(year)\n  districts &lt;- districts |&gt;\n    mutate(STATEFP = sprintf(\"%03d\",as.numeric(STATEFP))) |&gt;\n    inner_join(Unique_state, by = c(\"STATEFP\" = \"ID\"))\n  assign(variable_name,districts)\n}\n#similarly pulling in the Districts information by year available and the State_Name from the Unique_states above#\n\ndistricts_in_question &lt;- 1976:2022\n#Combining all districts processing into one#\nprocess_district &lt;- function(district_data) {\n  district_data |&gt;\n    group_by(STATENAME) |&gt;\n    mutate(geometry = st_make_valid(geometry),\n           STATENAME = toupper(STATENAME)) |&gt;\n    summarize(geometry = st_union(geometry), .groups = \"drop\")\n}\n#Creating the function to aggregate all the maps to State Level visualization\n\n# Example usage for a dynamically named variable\nfor (i in districts_in_question) {\n  # Construct the variable name\n  variable_name &lt;- paste0(\"districts\", sprintf(\"%04d\", i))\n  # Check if the variable exists and process it if it does\n  if (exists(variable_name, envir = .GlobalEnv)) {\n    # Get the data, process it, and assign it back to the variable\n    assign(variable_name, process_district(get(variable_name)))\n  }\n}\n#applying the loop to the function above and outputting as district-year\n\nfor (year in 1976:2022) {\n  # Dynamically create the table name\n  table_name &lt;- paste0(\"districts\", year)\n  \n  # Check if the table exists in the environment\n  if (exists(table_name)) {\n    # Get the table, add the Year column, and assign it back\n    temp_table &lt;- get(table_name)\n    temp_table$Year &lt;- year\n   assign(table_name, temp_table)\n  }\n}\n#Creating a column with the given year in each table\n\nyears &lt;- 1976:2022\n\n# Dynamically collect all tables into a list and bind them\ndistricts_combined &lt;- bind_rows(\n  lapply(years, function(year) {\n    table_name &lt;- paste0(\"districts\", year)\n    if (exists(table_name)) {\n      get(table_name)  # Retrieve each table by name\n    } else {\n      NULL  # Skip if the table doesn't exist\n    }\n  })\n)\n#creating code to aggregate all into a combined yearly analysis with the year in the file\n\nSince that has now all been aggregated and all the mapping has been brought into the r instance we are going to go through the visualization of the 2000 Presidential Election."
  },
  {
    "objectID": "mp03.html#what-are-the-ecv-allocation-schemes",
    "href": "mp03.html#what-are-the-ecv-allocation-schemes",
    "title": "Will Peters STA9750-2024-FALL MP03",
    "section": "What are the ECV Allocation Schemes?",
    "text": "What are the ECV Allocation Schemes?\n\nState-Wide Winner-Take All\nThis is using the approach that the top winning presidential candidate in that state gets all the seats in the State\n\nState_winner_take_all &lt;- President_votes |&gt;\n  group_by(state, year) |&gt;\n  # Filter for rows where candidatevotes matches the maximum for each state and year\n  filter(candidatevotes == max(candidatevotes, na.rm = TRUE)) |&gt;\n  select(state, year, party_simplified) |&gt;\n  left_join(\n    House_votes |&gt;\n      group_by(state, year) |&gt;\n      summarize(Num_districts = max(district, na.rm = FALSE) + 2) |&gt;\n      mutate(Num_districts = ifelse(Num_districts == 2, 3, Num_districts)),\n    by = c(\"state\", \"year\")\n  ) |&gt;\n  group_by(year, party_simplified) |&gt;\n  # Summarize the total Num_districts by party for each year\n  summarize(Num_districts = sum(Num_districts, na.rm = TRUE), .groups = \"drop\")\n\n\nggplot(State_winner_take_all, aes(x = year, y = Num_districts, color = party_simplified)) +\n  geom_line() +\n  labs(title = \"Seats won Over Time by Party\",\n       x = \"Year\",\n       y = \"Seats won\") +\n  theme_minimal() +\n  theme(\n    strip.text = element_text(size = 10),  # Adjust facet label text size\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n\n\nDistrict-Wide Winner-Take-All\nThis provides each state with each District going to the winning party, except for the additional State seats (2 seats) going to the majority presidential candidate in that state.\n\ndistrict_winner &lt;- House_votes |&gt;\n  group_by(state, district, year) |&gt;\n  # Use slice_max to keep the row with the maximum votes, including party_simplified\n  slice_max(order_by = candidatevotes, n = 1, with_ties = FALSE) |&gt;\n  # Select necessary columns\n  summarize(candidate = first(candidate),\n            party = first(party),  # Retain the party of the top candidate\n            district_ecvs = 1, .groups = \"drop\") |&gt;\n  group_by(year,party) |&gt;\n  summarize(seats_won = sum(district_ecvs, na.rm = TRUE))\n\nstate_winner &lt;- House_votes |&gt;\n  group_by(state, year, candidate, party) |&gt;\n  # Sum votes across all districts to get state-wide totals\n  summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  # Find the candidate with the highest state-wide vote\n  group_by(state, year) |&gt;\n  slice_max(order_by = total_votes, n = 1, with_ties = FALSE) |&gt;\n  # Assign two at-large ECVs to the state-wide winner\n  mutate(at_large_ecvs = 2) |&gt;\n  select(state, year, candidate, party, at_large_ecvs) |&gt;\n  group_by(year,party) |&gt;\n  summarize(seats_won = sum(at_large_ecvs,na.rm = TRUE))\n\ndistrict_and_state_winner_take_all &lt;- bind_rows(\n    district_winner |&gt; select(year, party, seats_won),\n    state_winner |&gt; select(year, party, seats_won)) |&gt;\n    group_by(year, party) |&gt;\n    # Sum up ECVs from districts and at-large for each candidate in each state\n    summarize(seats_won = sum(seats_won), .groups = \"drop\")\n  # Summarize district results\n\nggplot(district_and_state_winner_take_all, aes(x = year, y = seats_won, color = party)) +\n  geom_line() +\n  labs(title = \"Seats won Over Time by Party\",\n       x = \"Year\",\n       y = \"Seats won\") +\n  theme_minimal() +\n  theme(\n    strip.text = element_text(size = 10),  # Adjust facet label text size\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n\n\nState-Wide Proportional\nThis method applies the proportion of votes the candidate got across the number of seats to the individual state.\n\nstate_proportional &lt;- President_votes |&gt;\n  group_by(state, year) |&gt;\n  mutate(total_votes = sum(candidatevotes)) |&gt;\n  #Calculating number of votes at each candidate received by the number of total votes\n  left_join(House_votes |&gt;\n              group_by(state,year) |&gt;\n              summarize(Num_districts = max(district, na.rm = FALSE)+2)\n            ,join_by(\"state\",\"year\")) |&gt;\n  mutate(candidate_percentage = candidatevotes / total_votes,\n         candidate_ecvs = round(candidate_percentage * Num_districts)) |&gt;\n  select(state, year, candidate, candidate_ecvs, party_simplified) |&gt;\n  group_by(party_simplified,year) |&gt;\n  summarize(seats_won = sum(candidate_ecvs)) |&gt;\n  filter(seats_won != 0)\n\nggplot(state_proportional, aes(x = year, y = seats_won, color = party_simplified)) +\n  geom_line() +\n  labs(title = \"Seats won Over Time by Party\",\n       x = \"Year\",\n       y = \"Seats won\") +\n  theme_minimal() +\n  theme(\n    strip.text = element_text(size = 10),  # Adjust facet label text size\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n\n\nNational Proportional\nThis is pretty obvious as the majority rules logic, with the President getting the most votes winning the majority of seats.\n\nnational_proportional &lt;- President_votes |&gt;\n  group_by(candidate, year,party_simplified) |&gt;\n  summarize(candidate_total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(year) |&gt;\n  mutate(year_total_votes = sum(candidate_total_votes)) |&gt;\n  ungroup() |&gt;\n  mutate(national_percentage = candidate_total_votes / year_total_votes,\n         candidate_ecvs = round(national_percentage * 538)) |&gt;  # 538 total ECVs\n  filter(candidate_ecvs != 0) |&gt;\n  group_by(year,party_simplified) |&gt;\n  summarize(candidate_ecvs = sum(candidate_ecvs))\n\nggplot(national_proportional, aes(x = year, y = candidate_ecvs, color = party_simplified)) +\n  geom_line() +\n  labs(title = \"ECV Allocation Over Time by Party\",\n       x = \"Year\",\n       y = \"Electoral College Votes (ECVs)\") +\n  theme_minimal() +\n  theme(\n    strip.text = element_text(size = 10),  # Adjust facet label text size\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\nTake 1984 as a prime example the Republicans would have won in a popularity contest, being the national and state apportionment however it is clear that the Democrats won under the other two methodologies. Since it is representative of overall population in key areas it is right to say that the Democrats could make a claim to have won, however I think given the overwhelming republican popularity, they may have contested the election."
  },
  {
    "objectID": "mp03.html#footnotes",
    "href": "mp03.html#footnotes",
    "title": "Will Peters STA9750-2024-FALL MP03",
    "section": "Footnotes",
    "text": "Footnotes\n\nhttps://cdmaps.polisci.ucla.edu/↩︎\nhttps://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html↩︎\nMIT Election Data and Science Lab, 2017, “U.S. House 1976-2022,” https://doi.org/10.7910/DVN/IGOUN2, Harvard Dataverse, v13, UNF:6: Ky5FkettbvohjTSN/IvldA== [fileUNF].↩︎\nMIT Election Data and Science Lab, 2017, “U.S. President 1976-2020,” https://doi.org/10.7910/DVN/42MVDX, Harvard Dataverse, v8, UNF:6:F0opd1IRbeY190yVfzglUw== [fileUNF].↩︎"
  }
]